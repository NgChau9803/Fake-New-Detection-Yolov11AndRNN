# Dataset Configuration
data:
  fakeddit:
    files:
      - "data/raw/fakeddit/multimodal_test_public.tsv"
      - "data/raw/fakeddit/multimodal_train.tsv"
      - "data/raw/fakeddit/multimodal_validate.tsv"
    file_type: "tsv"
    label_mapping:
      real: 0
      fake: 1
    metadata_columns:
      - author
      - subreddit
      - domain
      - score
      - upvote_ratio
      - num_comments
    text_columns:
      - title
      - clean_title
    image_url_column: "image_url"
    id_column: "id"
    label_column: "2_way_label"
    preprocessing:
      text:
        max_length: 128
        padding: "max_length"
        truncation: true
      image:
        max_size: 224
        min_size: 32
        aspect_ratio_range: [0.75, 1.33]
        color_mode: "rgb"
        interpolation: "bilinear"
        rescale: 1.0/255.0
  
  fakenewnet:
    dataset_dir: "data/raw/fakenewnet"  # Base directory for the dataset
    sources: ["politifact", "gossipcop"]  # Available sources
    labels: ["fake", "real"]  # Available labels
    id_column: "id"
    text_column: "text"
    clean_text_column: "clean_text"
    image_url_column: "image_url"
    label_column: "label"
    metadata_columns:
      - "source"
      - "publish_date"
      - "source_url"
      - "authors"
      - "keywords"
      - "canonical_link"
      - "summary"
  
  processed_dir: "data/processed"
  images_dir: "data/images"
  cache_dir: "data/cache"
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  max_text_length: 100
  vocab_size: 10000
  balanced_sampling: true
  cache_features: true

# Model Configuration
model:
  text:
    embedding_dim: 300
    rnn_units: 128
    attention_heads: 4
    dropout_rate: 0.2
    recurrent_dropout: 0.1
    use_bidirectional: true
    use_layer_norm: true
    max_sequence_length: 128
    num_classes: 2  # Binary classification
  image:
    input_shape: [224, 224, 3]
    backbone: "yolov11-tiny"
    feature_dim: 512
    dropout_rate: 0.2
    use_attention: true
    num_classes: 2  # Binary classification
  fusion:
    fusion_method: "attention"
    hidden_dim: 256
    dropout_rate: 0.2
    num_heads: 4
    use_residual: true
    use_layer_norm: true
    num_classes: 2  # Binary classification
  
# Training Configuration
training:
  batch_size: 32
  epochs: 10
  learning_rate: 0.001
  early_stopping_patience: 3
  use_class_weights: true
  optimizer: "adam"
  optimizer_config:
    beta_1: 0.9
    beta_2: 0.999
    epsilon: 1e-07
  lr_schedule:
    enabled: true
    decay_rate: 0.9
    decay_steps: 1000
    warmup_steps: 100
  gradient_clipping:
    enabled: true
    clip_norm: 1.0
  mixed_precision: true
  
# Evaluation Configuration
evaluation:
  metrics: ["accuracy", "precision", "recall", "f1", "auc"]
  num_explanation_samples: 5
  cross_dataset_validation: true
  confusion_matrix: true
  classification_report: true
  visualization:
    attention_maps: true
    feature_maps: true
    class_activation_maps: true
    token_importance: true
    save_format: "png"
    dpi: 300
    colormap: "viridis"
    overlay_alpha: 0.5 